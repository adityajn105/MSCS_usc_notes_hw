{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Intelligent Agents\n",
    "\n",
    "\"Rationality\" refers to ability to make good decisions given the sensor information received.\n",
    "\n",
    "### PEAS description for task environment\n",
    "1. Performance Measure (depends on what agent want to aspire)\n",
    "2. Environement (what environemnt the agent is in)\n",
    "3. Actuators (how agent takes action in environment)\n",
    "4. Sensors (how agent perceives environment)\n",
    "\n",
    "\n",
    "### Types of environment\n",
    "1. Fully observable vs Partially observable - possible to determine complete state of environment\n",
    "2. Accessible vs inaccessible- agents sensors can have access complete state of environment (real world is not accessible because of hiesenberg uncertainity priciple)\n",
    "2. Single agent vs multi agent - obvious\n",
    "3. Determinisitc vs stochastic (nondeterministic) - no randomness\n",
    "4. Episodic vs Sequential (non sequential) - current action do no depend on previous state, only on current state\n",
    "5. Static vs dynamic - obvious\n",
    "6. Discrete vs continouus - limited number of distinct clearly defined state\n",
    "7. Known vs Unknown (not same as fully and partially observable) - outcome of all actions are known+\n",
    "\n",
    "**Agent Function**: A function that specifies the agent’s action in response to every possible percept sequence.\n",
    "\n",
    "**Agent Program**: that program which, combined with a machine architecture, implements an agent function. In our simple designs, the program takes a new percept on each invocation and returns an action. \n",
    "\n",
    "### Types of Agent (take a look at psuedo code)\n",
    "1. Simple Reflex Agent (select action based on current percept ignore percept history)\n",
    "2. Model-based reflex agent (It keeps track of the current state of the world)\n",
    "3. Goal based Agent (It keeps track of the world as well as a set of goals it is trying to achieve)\n",
    "```\n",
    " implicit goal = No Dirt\n",
    " explicit goal = at San Diego\n",
    "```\n",
    "4. Utility-based agents (It uses model of world along with a utility function that meansures its preformace among states of world.)\n",
    "5. Learning Agent (adapt to environment, learn from mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3 : Solving Problems by Searching\n",
    "\n",
    "**Completeness** :  Algorithm will lead to a solution if there exists one.\n",
    "\n",
    "**Optimality** : Strategy finds an optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS (uninformed)\n",
    "  \n",
    "  * Time Complexity : O($b^d$)\n",
    "  * Space Complexity : O($b^d$)\n",
    "  * Completeness : Yes\n",
    "  * Optimality: Yes\n",
    "  \n",
    "### DFS (uninformed)\n",
    "   \n",
    "  * Time Complexity : O($b^d$)\n",
    "  * Space Complexity : O($bd$)\n",
    "  * Completeness: No (Yes, visited nodes are maintained (graph version dfs))\n",
    "  * Optimality : No\n",
    "\n",
    "### Uniform Cost Search (uninformed)\n",
    "    Like a bfs but all edges are not of equal length. only uses g(n)\n",
    "    f(n)  = g(n)\n",
    "    \n",
    "  * Time Complexity : O($b^d$)\n",
    "  * Space Complexity : O($b^d$)\n",
    "  * Completeness : Yes, provided if every edge has some positive constant. if edge cost is zero it can stuck in infinite loop\n",
    "  * Optimality : Yes\n",
    "  \n",
    "### Depth Limited Search (uninformed)\n",
    "    Because DFS fails in infinte search space, therefore we use depth limited search with depth limit l.\n",
    "    \n",
    "   * Time Complexity : O($b^l$)\n",
    "   * Space Complexity : O($bl$)\n",
    "   * Completeness : No, goal can be at more depth that l\n",
    "   * Optimality : No\n",
    "\n",
    "### Iterative Deepening Search (uninformed)\n",
    "    we iteratively increase depth limit\n",
    "    \n",
    "   * Time Complexity : O($b^d$)\n",
    "   * Space Complexity : O($bd$)\n",
    "   * Completeness : Yes\n",
    "   * Optimal : Yes\n",
    "   \n",
    "### Bidirectional (uninformed)\n",
    "    We start from start as well as goal node in both directions\n",
    "   \n",
    "   * Time Complexity : O($b^{d/2}$)\n",
    "   * Space Complexity : O($b^{d/2}$)\n",
    "   * Completeness : Yes\n",
    "   * Optimal : Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Search (infomed)\n",
    "    Uses cost that is equal to just heuristic to make decisions\n",
    "    f(n) = h(n)\n",
    "    \n",
    "   * Time Complexity : O($b^m$), depend on heuristic\n",
    "   * Space Complexity : O($b^m$)\n",
    "   * Completeness : No, (yes, with state checking, avoid repeating same state)\n",
    "   * Optimal : No\n",
    "   \n",
    "### A* Search (informed)\n",
    "    Uses cost that is equal path cost + heuristic to make decisions about next node.\n",
    "    f(n) = g(n) + h(n)\n",
    "    \n",
    "   * Time Complexity : exponential in [(relative error in h) x (length of solution)]\n",
    "   * Space Complexity : O()\n",
    "   * Completeness : Yes\n",
    "   * Optimality: Conditional ( heurisitc must be admissible )\n",
    "   \n",
    "   \n",
    "**Admissible Heuristic** :  A heuristic that never overestimates the cost to reach the goal.\n",
    "      \n",
    "    h(n) <= true_cost   \n",
    "\n",
    "**Consistent Heurisitic** : A heuristic is consistent if for every node n and every successor n'. The estimate cost of reaching the goal from n is no greater than step cost of getting to n' plus the estimated cost of reaching the goal from n'. This is form of general **triangle inequality**.\n",
    "           \n",
    "    h(n) <= C(n,n') + h(n')\n",
    "    \n",
    "    \n",
    "    eg: [n : g=5, h=4, f=9]    [n' : g=6, h'=2, f'=8]    [C(n,n') : 1]               \n",
    "    Pathmax : f(n') = max( g(n') + h(n'), f(n) )\n",
    " \n",
    "**Important Points**   \n",
    "   * Consistent Heuristic is always admissible but converse is not true.\n",
    "   * With an admissible but inconsistent heuristic, A* requires some extra bookeeping to ensure optimality. (pathmax)\n",
    "   \n",
    "**Proof of optimality** :\n",
    "                                  \n",
    "         s                              f(G2) = g(G2)  Since h(G2) = 0                                            \n",
    "        / \\                                   > g(G1)  Since G2 is suboptimal                                \n",
    "       -----                                  >= f(n)  Since h is admissible                    \n",
    "      /     \\                                                                              \n",
    "     n       G2                     So, f(G2) > f(n)   A* will never select G2 for expansionism                       /\n",
    "    G1\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Search (when path to goal doesnt matter)\n",
    "\n",
    "**Advantages**\n",
    "1. They use very little memory - ususally constant\n",
    "2. they can often find solution in large or continuous state spaces\n",
    "\n",
    "#### Hill Climbing (greedy local search)\n",
    "Loop that continuously moves in direction of increasing value. Terminates when reaches a \"peak\" where no neighbor has a higher value.\n",
    "\n",
    "Do not look ahead and only stores current node as a state and value of objective function.\n",
    "\n",
    "This can stuck in 1. Local Maxima, 2. Ridges (seq of local maxima) 3. Plateau (flat area)\n",
    "\n",
    "For this \n",
    "1. **stochastic hill climbing** : chooses a random from among uphill moves, probability of selection vary with stepness of uphill moves.\n",
    "2. **First Choice hill climbing** : generating successor randomly untill one is generated that is better than current state. (simualted annealing with T=0)\n",
    "3. **Random-restart hill** : conducts a series of hill-climbing search from randlomly generted initial states.\n",
    "\n",
    "Complete : No (can stuck in local maxima)\n",
    "\n",
    "\n",
    "#### Simulated Annealing \n",
    "Hill climbing combined with random walk.\n",
    "\n",
    "Think of this as gradient descent of a ping-pong ball, if ball stuck in local minima we shake the hard enough to bounce the ball out of local minima but nor hard enough to bounce out of local maxima. Initially we start by shaking hard (high temperature) and then gradually reduce the intensity of shaking (low temperature).\n",
    "\n",
    "\n",
    "```\n",
    "current <- MAKE-NODE( problem.initial_state )\n",
    "for t in 1 to inf\n",
    "    T <- schedule(t)\n",
    "    if T = 0 then return current\n",
    "    next <- a randomly selected successor of current\n",
    "    del E <- next.value - current.value\n",
    "    if del E > 0 then current <- next\n",
    "    else current <- next only with probability e^{ del E / T }\n",
    "                                                                                                    \n",
    "\n",
    "Large T                                                                    Small T\n",
    " \n",
    "del E < 0                                                                  del E < 0 \n",
    "del E / T < 0 and very small                                               del E / T is large\n",
    "e^{del E / T} close to 1                                                   e^{del E/ T} close to 0\n",
    "accept bad move with high probability                                      accept bad with low probability\n",
    "Like a random move                                                         Like a carefull walk                   \n",
    "                                                                                                       \n",
    "```\n",
    "\n",
    "#### Local beam Search\n",
    "Keeps track of k states rather than just one. Begins with k randomly generated states. At each step, all the successor of k states are generated. If any one is a goal, algo halts. Otherwise repeats the process.\n",
    "\n",
    "K successor can be searched independently in parallel threads. However, useful information is passed among the prallel search threads. All process are not independ as in random-restart hill climbing.\n",
    "\n",
    "However selected k states may lack diversity, so a variant called stochastic beam search is used.\n",
    "\n",
    "#### Genetic Algorithms\n",
    "Successor states are generted by combining 2 parent rather than modifying a single state. It represents problem like a DNA sequence. define fitness (objective function) for each candidate solution.\n",
    "\n",
    "Probabilty of reproducing is directly proportional to the fitness score. For each pair to be mated, following operations can be used.\n",
    "\n",
    "1. CrossOver - exchange information throug same part of information\n",
    "2. Mutation - randomly twiddle with genes with probabitly\n",
    "3. Cataclysm - Kill n% of population and create a fresh set of candidates\n",
    "4. Annealing of mating pairs - accept mating of suboptimal pairs with some probabilty\n",
    "\n",
    "GA is superb if\n",
    "- your space is loaded with lot of weird bumbs and local minima\n",
    "- you dont quite understand underlying process of problem space\n",
    "- you have lot of processor (parallelism is easy in GA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And-Or Trees (With non-deterministic environment)\n",
    "\n",
    "In deterministic environment, the only branching is introduced by agent's own choice in each state. We call these nodes OR nodes. In non-deterministic world. branching is also introduced by environment's choice. We call these AND nodes.\n",
    "\n",
    "            Pg: 136\n",
    "            state 1 (OR)\n",
    "             /  \\\n",
    "      suck  /    \\ Right\n",
    "           /      \\\n",
    "         AND      AND\n",
    "        /  \\       / \\  \n",
    "       /    \\\n",
    "    state 2  state 3   \n",
    "\n",
    "    Algorithm on Pg 137. (And-Or search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax Algorithm\n",
    "\n",
    "Performs a depth first exploration of the game tree.\n",
    "\n",
    "If maximum depth of tree is m and b legal moves at each point\n",
    "Time Complexity : O(b^m)\n",
    "Space Complexity : O(bm) or O(m) if one action at a time\n",
    "\n",
    "\n",
    "### Alpha-Beta Pruning\n",
    "\n",
    "* Problem with minimax search is that the number of game state it has to examine is exponential in the depth of the tree. Unfortunately we cant eliminate the exponenet, but it turns out we can effectively cut it in half. \n",
    "\n",
    "* Alpha-Beta prunes away the branches that could not possible influence the final decision.\n",
    "\n",
    "* Alpha-Beta pruning get its name from the following 2 parameters that describe the bound\n",
    "\n",
    "$\\alpha$ : the value of the best (i.e. highest value) choice we have found so far at any choice point along path for MAX. **The meaning of the alpha value is “the least value that Max can already get”**.\n",
    "\n",
    "$\\beta$ : the value of the best (i.e. lowest value) choice we have found so far at any choice point along the path for MIN. **The meaning of the beta value is “the maximum value that Min would give so far”.**\n",
    "\n",
    "\n",
    "                                            Thumb Rule\n",
    "\n",
    "                                    check                          update\n",
    "                                 ------------------------------------------------\n",
    "                            Min     alpha (v<=alpha)           beta (minimize)\n",
    "\n",
    "                            Max     beta (v>=beta)           alpha (maximize)\n",
    "\n",
    "```\n",
    "func AlphaBeta-Decision(state)\n",
    "    v <- Max-Value(state, -inf, inf)\n",
    "    return action in Actions(state) with value v\n",
    "\n",
    "func Max-Value(state, alpha, beta)\n",
    "    if Terminal-Test(state) then return Utility(state)\n",
    "    v <- -inf\n",
    "    for each a in Action(state) do\n",
    "        v <- max( v, Min-Value( Result(s,a), alpha, beta ) )\n",
    "        if v >= beta then return v \n",
    "        alpha <- max(alpha, v)\n",
    "    return v\n",
    "       \n",
    "func Min-Value(state, alpha, beta)\n",
    "    if Terminal-Test(state) then return Utility(state)\n",
    "    v <- inf\n",
    "    for each a in Action(state) do\n",
    "        v <- min( v, Max-Value( Result(s, a), alpha, beta ) )\n",
    "        if v <= alpha then return v\n",
    "        beta <- min(beta, v)\n",
    "    return v\n",
    "```\n",
    "\n",
    "### Imperfect Real-Time Decisions\n",
    "\n",
    "The depth to be searched in MiniMax is not practical, instead program should cut off the search earlier and apply a heuristic functions to state in the search, effectively turning non-terminal nodes into terminal leaves. \n",
    "\n",
    "1. Replace the **utility function by a heuristic evaluation** function EVAL, which estimates the positions utiltiy, and replace **terminal test by a cutoff test** that decides when to apply EVAL. Exact values of EVAL do not matter, but it should be monotonic to preserve behaviour.\n",
    "\n",
    "```\n",
    "H-MINIMAX(s,d) = \n",
    "        EVAL(s)                                            if CUTOFF-TEST(s,d)\n",
    "        max_a Actions(s) H-MINIMAX(RESULT(s,a), d+1)       if Player(s) = MAX\n",
    "        min_a Actions(s) H-MINIMAX(RESULT(s,a), d+1)       if Players(s) = MIN\n",
    "```\n",
    "\n",
    "2. Use **Beam Search**, consider only a \"beam\" of best n moves rather than all possible moves.\n",
    "\n",
    "3. **Search vs Lookup**, Many game-playing programs use table lookup ratger than search for opening and ending of games. For opening most rely on experise of humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Games (EXPECTIMINIMAX)\n",
    "\n",
    "* Many games mirror undepredictability by including random element, such as throwing of dice. These games must include **chance nodes** in addition to MAX and MIN nodes. Chance nodes are shown in circles. The branch leading from each node denote the possible random chances (like all possible rolls of die).\n",
    "\n",
    "\n",
    "* However each chance do not have same probability. So posiitons do not have definite minimax values. Instead we can only calculate the **expected value** of a position: the average over all possible outcomes of the chance nodes.\n",
    "\n",
    "\n",
    "* This lead us to generalize minimax value for determinisitc games to an **expecti-minimax value** for games with chance nodes. Terminal nodes and Max and Min nodes work exactly the same way as before. For **chance nodes the expected value** is the sum of values over all outcomes, wighted by the probabiltiy of each chance actions.\n",
    "\n",
    "    EXPECTIMINIMAX(s)= \n",
    "        UTILITY(s)                                 if TERMINAL-TEST(s)\n",
    "        max_a EXPECTIMINIMAX( RESULT(s, a) )       if PLAYER(s) = MAX\n",
    "        min_a EXPECTIMINIMA( RESULT(s,a) )         if PLAYER(s) = MIN\n",
    "        sum_P(r) EXPECTIMINIMAX(RESULT(s,r))       if PLAYER(s) = CHANCE\n",
    "        \n",
    "        \n",
    "* Evaluation function must be a positive linear transformation of the probability of winning from a position,\n",
    "\n",
    "\n",
    "* Time Complexity  O($b^m n^m$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint Satisfaction Problems\n",
    "\n",
    "A CSP consists of three components X, D and C. X is a set of variables, D is a set of domains, C is a set constraints that specify allowable combinations of values.\n",
    "\n",
    "1. An assignment that does not violate any constraints is called a consistent or legal assignment.\n",
    "2. A complete assignment is one in which every variable is assigned and a solution to a CSP is a consistent, complete assignment.\n",
    "3. CSP with continous domain are common in the real world, example linear programming problems, where constraints must be linear equalities and inequalitites.\n",
    "\n",
    "\n",
    "**Urany constraint :** restrict value of single variable (SA $\\ne$ green)\n",
    "\n",
    "**Binary constraint :** relates 2 variable ( SA $\\ne$ NSW )\n",
    "\n",
    "**Ternary constraint :** between 3 variables ($ X < Y <Z $)\n",
    "\n",
    "**Global constraint :** involves arbitary number of variables\n",
    "\n",
    "In CSP there is a choice, an algorithm can searchor do a specific type of inference called **Constraint propogation.** \n",
    "\n",
    "\n",
    "### Local Consistency\n",
    "\n",
    "Treat each variable as a node in graph, and each binary constraint as an arcm then process of enforcing local consistency in each part of graph causes inconsistent values to be eliminated.\n",
    "\n",
    "**Node Consistency :** \n",
    "\n",
    "A single variable is node consistent if all the values in variable domain satisfy the variable unary constraints. eg. SA dont like green\n",
    "\n",
    "Network is node consistent if every variable in network is node consistent.\n",
    "\n",
    "**Arc Consistency :**\n",
    "\n",
    "A variable is arc-consistent if every value in domain satisfy binary constraints.\n",
    "\n",
    "More formally $X_i$ is arc-consistent with respect to another variable $X_j$ if for every value in current domain $D_j$ that satisfies the binary constraint on the arc ($X_i, X_j$).\n",
    "\n",
    "```\n",
    "function AC-3(csp) returns false if an inconsistency is found and true otherwise\n",
    "    inputs: csp, a binary CSP with components(X, D, C)\n",
    "    local variables: queue of arcs initially all arc in csp\n",
    "    \n",
    "    while queue is not empty do\n",
    "        (Xi, Xj) <- Remove-First(queue)\n",
    "        if Revise(csp, Xi, Xj) then\n",
    "            if size of Di = 0 then return false\n",
    "            for each Xk in Xi.Neighbors - {Xj}:\n",
    "                add (Xk, Xi) to queue\n",
    "    return True\n",
    "    \n",
    "function Revise(csp, Xi, Xj) returns true iff we revise the domain of Xi\n",
    "    revised <- false\n",
    "    for each x in Di do\n",
    "        if no value y in Dj allows (x,y) to satisfy the constraint between Xi and Xj then\n",
    "            delete x from Di\n",
    "            revised <- true\n",
    "    return revised\n",
    "\n",
    "```\n",
    "Time Complexity : $O(n^2d^3)$ n variable,s d values\n",
    "\n",
    "**Path Consistency**\n",
    "\n",
    "Arc consistency can help in reducing the domain of variables sometimes even finding a solution. But for other networks arc consistency fails to make enough inferences. For example in map coloring problem with only 2 color allowed, arc consistency can do nothing as every variable is already arc consistent.But clearly there is no solution to the problem because WA, NT, and SA all touvh each other.\n",
    "\n",
    "Path consistency tightens the binary constraints by using implicit constraints that are inferred by looking at triplets of variables. A 2 variable set {Xi, Xj} is path consistent with respect to third variable Xm, if for every assignment {Xi = a, Xj = b} consistent with the constraints on {Xi, Xj} there is an assignment to Xm that satisfies constraints on {Xi, Xm} and {Xm, Xj}.\n",
    "\n",
    "This is called path consistency because one can think of it as path from Xi to Xj with Xm in middle. PC-2 algorithm is used.\n",
    "\n",
    "**k-consistency**\n",
    "\n",
    "A CSP is k-consistent if for any set of k-1 variable and for any consistent assignment to those variable, a consistent value can always be assigned to kth variable.\n",
    "\n",
    "1-consistent : node consistency\n",
    "2-consistent : arc consistency\n",
    "3-consistent : path consistency\n",
    "\n",
    "A CSP is strongly k-consistent if it is k-consistent and is also (k-1) consistent, (k-2) consistent...all the way down to 1-consistent.\n",
    "\n",
    "**Global Constraints**\n",
    "\n",
    "Occur commonly, like AllDiff constraint that says all variable involved must be distinct. AllDiff inconsistency works as follows: if m variables are involved in the constraint and if they have n possible distinct values together, and m > n, then the constraint cannot be satisfied.\n",
    "\n",
    "For large resource-limited problems with integer values domains are represented by upper and lower bounds and are managed by bounds propogation. We say CSP is bound consistent.\n",
    "\n",
    "### Backtracking Search for CSP (DFS)\n",
    "\n",
    "A CSP with n variables and domain size d, the branching factor at top level is nd because any of d values can be assigned to any one of n variales. At next level it is (n-1)d and so on for n levels. We generate a tree with $n!.d^n$ leaves. But all CSP are commutative, so we only have to select only single node at top of search tree, because order of selecting node have no effect on outcome. With this restriction, the number of leaves is $d^n$.\n",
    "\n",
    "Backtracking search keeps only a single representation of a state and alters that representation rather than creating new one.\n",
    "\n",
    "* **Variable Ordering- Minimum Remaining Value (MRV)**\n",
    "The simplest strategy for selecting unassigned variable is to choose the next unassigned varaible in order of fewest \"legal\" values (Minimum remaining values). This is called **\"fail first\" or \"most constrained variable\" heuristic**. This works beacuase this strategy picks a varible that is more likely to cause a failure and helps in pruning the search tree.\n",
    " \n",
    "MRV doesnt help at all on choosing first variable (eg in map coloring, every region has 3 legal colors). **Degree heuristic** can reduce branching factor by selecting variable that is invovled in largest number of constraints on other unassigned variables.  \n",
    " \n",
    "* **Value Ordering - Least constraining value**\n",
    "Once a variable is selected, algo must decide the order in which to examine the values. **Least-constraining-value heuristic** prefers the value that rules out the fewer choices for the neighbors variables in the contraint graph.\n",
    "\n",
    "\n",
    "* **Why variable ordering is fail-first and value ordering is fail-last**\n",
    "MRV helps in minimizeing number of nodes in search tree by pruning large part of trees. For value ordering we want only 1 solution, it makes sense to work for most likely values first. If we want all solutions then value ordering would be irrelevant.\n",
    "\n",
    "#### Interleaving search and inferences\n",
    "\n",
    "AC-3 and other algorithm can infer reductions in domain of variables before we begin search. Also everytime we make a choice of a value for a variable we have a new opportunity to infer new domain reduction on neighboring variables.\n",
    "\n",
    "* **Forward Checking**\n",
    "\n",
    "Whenever a variable X is assigned, the forward-checking establishes arc consistency for it, for each unassigned variable Y that is connected to X by a constraint, delete from Y's domain any value that is inconsistent with the value chosen for X.\n",
    "\n",
    "Forward checking detects many inconsistencies, it does not detect all of them. It makes current variable arc-consistent but does not look ahead and make other variables arc-consistent. **MAC- Maintaining Arc Consistency** detects this inconsistency. After a variable Xi is assigned the inference procedure calls AC-3 but instead of all arcs in queue,we start with arcs (Xj, Xi) for all Xj that are unassigned. If AC-3 an empty domain, it returns false and then we backtrack.\n",
    "\n",
    "* **Intelligent Backtracking**\n",
    "\n",
    "Current backtracking is chronological backtracking because the most recent decision point is revised. Instead of this, **we backtrack to a variable that might fix the problem** - a variable that was responsible for making one of the possible values of last variable impossible.\n",
    "\n",
    "We keep track of set of assignments that are inconflict with current variable, we call it **conflict set**. The **BackJumping** method backtracks to the most recent assignment in the conflict set. While doing forward checking based on assignment X = x deletes a value form Y's domain, it should add X=x to Y's conflict set. However simple backjumping is redundant in a forward checking search or indeed MAC.\n",
    "\n",
    "* **Conflict-directed backjumping**\n",
    "\n",
    "Consider partial assignment {WA = red, NSW=red}, next we try to assign T and then NT, Q, V, SA. We know no assignmenet can work for these last 4 variables, so eventually we run out of values to try at NT. Backjumping cannot work because NT does not have complete set of preceding variables that caused it to fail. We know however that 4 variables NT, Q, V and SA taken together failed becauase of set of preceding variables.\n",
    "\n",
    "In our example firstly SA failed its conflict set was {WA, NT, Q}. We backjump to Q and Q absorbs conflict set from SA into into its own conflict set {NSW, NT}, the new conflict set is {WA, NSW, NT}. Now we backtrack to NT, the most recent of these. NT absorbs {WA, NSW} into its own direct conflict set {WA}, giving {WA, NSW}. The algorithm backjumps to NSW.\n",
    "\n",
    "To summarize let Xj be the current variable and let conf(Xj) be its conflict set. If every possible value of Xj fails, backjump to the most recent variable Xi in conf(Xj) and set\n",
    "\n",
    "$$ conf(Xi) \\leftarrow conf(Xi) \\cup conf(Xj) - \\{Xi\\}$$\n",
    "\n",
    "### Local Search for CSP\n",
    "\n",
    "Initial state assigns a value to every variable and searches changes the value of one variable at a time.\n",
    "\n",
    "Steps:\n",
    "1. Choose a variable randomly that is conflicted\n",
    "2. Assign a value to that variable that minimizes conflict.\n",
    "3. if current a solution return current else go to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepositional Logic\n",
    "\n",
    "**Knowledge Based Agents**\n",
    "\n",
    "Central componenet of knowledge based agent is its knowledge base or KB. A knowledge base is a set of sentences. Each sentence is expressed in a language called a knowledge representation langauge. \n",
    "\n",
    "There is way to add new sentence to KB and to query what is known. Standard names of these are TELL and ASK. Both of these operations may involve inference, that is deriving new sentence from old. When one Asks a question of the knowledge base, the answer should follow what has been told (TELLed) to KB previously.\n",
    "\n",
    "Agent program does 3 things. First it TELLs the knowledge base what it perceives. Second it ASKs the KB what action it should perform. In the process of answering query, extensive reasoning may be done. Third agent program TELL the KB which action was chosen and the agent executes the action.\n",
    "\n",
    "**Entailment**\n",
    "\n",
    "If a sentence is true in model m, we can say that m satisfies $\\alpha$ or sometimes m is a model of $\\alpha$.\n",
    "\n",
    "M($\\alpha$) mean set of all models of $\\alpha$. \n",
    "\n",
    "Entailement idea is that a sentence follows logically from another sentence or $\\alpha$ entails $\\beta$. The formal definition of entailment is this:\n",
    "\n",
    "$ \\alpha \\models \\beta \\text{ if and only if } M(\\alpha) \\subseteq M(\\beta) $\n",
    "\n",
    "$\\alpha$ is a stronger assertion on $\\beta$\n",
    "\n",
    "For example, Figure 7.5 agent perceives nothing in [1,1] and a breeze in [2,1]. These percepts combined with the agent knowledge of the rules of wumpus world, consitute the KB. Now let us consider 2 possible conclusions:\n",
    "\n",
    "$ \\alpha_1 = \\text{There is no pit in [1,2]} $\n",
    "\n",
    "$ \\alpha_2 = \\text{There is no pit in [2,2]} $\n",
    "\n",
    "in every model in which KB is true $\\alpha_1$ is also true, therefore $ KB \\models \\alpha_1 $\n",
    "\n",
    "in some models in which KB is true, $\\alpha_2$ is true, therefore $ KB \\nvDash \\alpha_2 $\n",
    "\n",
    "\n",
    "**Inference**\n",
    "\n",
    "An inference is deriving $\\alpha$ from KB. \n",
    "\n",
    "$ KB \\vDash_i \\alpha, \\; \\text{ $\\alpha$ is derived from KB by $i$ }$\n",
    "\n",
    "An inference algorithm that derives only entailed sentence is called **Sound** or truth preserving. It is highly desirable property. Unsound inference procedure essentially make things up as it goes along.\n",
    "\n",
    " $$ \\text{Soundness : whenever } KB \\vDash_i \\alpha, \\text{ then } KB \\models \\alpha \\text{ is true, derivation produces only entailed sentence.} $$\n",
    "\n",
    "\n",
    "**Completeness** is also desirable. A inference algorithm is complete if it can derive any sentence that is entailed.\n",
    "\n",
    "$$ \\text{Completeness : whenever } KB \\models \\alpha \\text{ then } KB \\vDash_i \\alpha \\text{ derivation can produce all entailed sentences. } $$\n",
    "\n",
    "**Equivilent :** If 2 sentence $\\alpha$ and $\\beta$ are equivilant only if each of them entails the other.\n",
    "\n",
    "$$ \\alpha \\equiv \\beta \\text{ if and only if $\\alpha \\models \\beta $ and $ \\beta \\models \\alpha $ }  $$\n",
    "\n",
    "**Validity :** A sentence is valid if it true in al models. Also known as tautologies - they are necessarily true.\n",
    "\n",
    "**Deduction Theorem :** For any sentence $\\alpha \\models \\beta$ if and only if sentence $\\alpha \\implies \\beta$ in all models. \n",
    "\n",
    "$$ \\alpha \\models \\beta \\text{ if and only if the sentence } \\alpha \\implies \\beta \\text{ is valid} $$\n",
    "\n",
    "**Satisfiability :** A sentence is satisfiable if it is true on or satisfied by some model.\n",
    "\n",
    "Validity and Satisfiablity are of course connected: \n",
    "\n",
    "1. $\\alpha$ is valid iff $\\neg \\alpha$ is unsatisfiable\n",
    "2. $\\alpha$ is satisfiable iff $\\neg \\alpha$ is not valid.\n",
    "\n",
    "$$ \\alpha \\models \\beta \\text{ if and only if the sentence } (\\alpha \\Lambda \\neg \\beta) is unsatisfiable $$\n",
    "\n",
    "if $ (\\alpha \\Lambda \\neg \\beta) \\text{ is unsatisfiable then } \\neg (\\alpha \\Lambda \\neg \\beta) \\text{ is valid }, \\neg \\alpha V \\beta \\text{ is valid }, \\alpha \\implies \\beta$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Order Logic\n",
    "\n",
    "* $\\implies$ is main connective to use with $\\forall$ \n",
    "* $\\wedge$ is main connective to use with $\\exists$\n",
    "\n",
    "* $\\forall x \\neg P \\equiv \\neg \\exists x P$\n",
    "* $\\neg \\forall P \\equiv \\exists x \\neg P$\n",
    "* $\\forall P \\equiv \\neg \\exists x \\neg P$\n",
    "* $\\exists x P \\equiv \\neg \\forall x \\neg P$\n",
    "* $\\neg(P \\vee Q) \\equiv \\neg P \\wedge \\neg Q$\n",
    "* $\\neg(P \\wedge Q) \\equiv \\neg P \\vee \\neg Q$\n",
    "* $P \\wedge Q \\equiv \\neg (\\neg P \\vee \\neg Q)$\n",
    "* $P \\vee Q \\equiv \\neg(\\neg P \\wedge \\neg Q)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference in FOL\n",
    "\n",
    "FOL inference via **propositionlization** is complete i.e. any entailed sentence can be proved. But we dont know untill the proof is done that the sentence is entailed.\n",
    "\n",
    "**Generalized Modus Ponens**\n",
    "\n",
    "Requires sentences to be Horn From. \n",
    "\n",
    "a) Atomic   \n",
    "\n",
    "b) an implication of conjunction of atomic sentences as the antecedent and atom as the consequent.\n",
    "\n",
    "**Forward Chaining**\n",
    "\n",
    "It is like a breadth first search at top level, with DFS at sub-searches. KB must be organized in efficient manner to enable efficient searches.\n",
    "\n",
    "**Backward Chaining**\n",
    "\n",
    "It is like a depth first search. In KB of realistic size it will result in failure.\n",
    "\n",
    "**Completeness**\n",
    "\n",
    "A sentence can be proved if it is entailed by another set of sentences. Having complete algorithm is a big deal since arbitarily deeply nested functions combined with universally quantification make infinite search space.\n",
    "\n",
    "Procedure i is complete if and only if $ KB \\vdash_i \\alpha$ whenever $KB \\models \\alpha$\n",
    "\n",
    "Forward and backward chaining are complete for Horn KBs (definite clauses), but incomplete for general First Order logic because they can stuck in infinite loops.\n",
    "\n",
    "Entailment in FOL is semi-decidable because algorithm exists to prove entailment, but no algorithm exists that tells sentence is not entailed.\n",
    "\n",
    "**Resolution**\n",
    "\n",
    "It is a complete inference algorithm, It uses conjunctive normal form. \n",
    "\n",
    "A FOL can be converted to CNF using foloowing steps.\n",
    "\n",
    "1. Eliminate Implications. (Replace P -> Q with ~P v Q)\n",
    "2. Move ~ inwards. ( $~\\forall x \\; p \\; becomes \\; \\exists x\\;~p$ and $ ~\\exists x\\;p \\; becomes \\; \\forall x\\; ~ p $ )\n",
    "3. Standardize variables. Sentence which use same variable name twice, change the name of one of the variables.\n",
    "4. Move quantifiers left in order. $ \\forall x P \\text{ v } \\exists x Q \\; $ becomes $\\forall x \\exists y P \\text{ v } Q$\n",
    "5. Eliminate $\\exists$ by Skolemization: \n",
    "    \n",
    "    $\\exists x P(x)$ into $P(A)$ where A is new constant. However if we blindly apply the rule to 2 matching parts we get.\n",
    "    \n",
    "   \"Everyone has a heart.\" -> $\\forall\\;x Person(x) \\implies \\exists\\;y Heart(y) \\wedge Has(x, y) $\n",
    "   \n",
    "   Wrong Skolemization -> $\\forall x Person(x) \\implies Heart(H1) \\wedge Heart(x,H1) $, which implies everyone has a same heart.\n",
    "   \n",
    "   Right Skolemization -> $\\forall x Person(x) \\implies Heart(H(x)) \\wedge Heart(x,H(x)) $ here H is a skolem function.\n",
    "\n",
    "6. Drop universal quantifiers\n",
    "7. Distribute $\\vee$ over $\\wedge$\n",
    "\n",
    "Inference Rule - Resolution rule for FOL is simply a lifted version of the prepositional resolution rule.\n",
    "\n",
    "$$ \\frac{p_1 \\vee p_2 ... \\vee p_m, \\; q_1 \\vee q_2 ... \\vee q_n}{(p_1 \\vee p_2 ... \\vee p_m \\vee q_1 ... \\vee q_n)\\sigma } $$\n",
    "where $ p_j \\sigma = \\neg q_k \\sigma $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning\n",
    "\n",
    "**Planner** : ask for sequence of actions that makrs goal true if executed.\n",
    "\n",
    "**Theorem Prover** : ask whether query sentence is true given KB.\n",
    "\n",
    "Strips Language is a tidily arranged action descriptions, restricted langauge.\n",
    "```\n",
    "    Actions : Buy(x)\n",
    "    Precondition : At(p), Sells(p,x)\n",
    "    Effect : Have(x)\n",
    "```\n",
    "\n",
    "**Types of Planner**\n",
    "Situation Space Planner : Search through all possible solutions\n",
    "\n",
    "Progression Planner : Start with initial state, apply operator untill goal is reached. Has Problem with high branching factor.\n",
    "\n",
    "Regression Planenr : Start from goal state and apply operator untill start state is reached.\n",
    "\n",
    "**Standard Search vs Planning Search**: in standard search node is concrete world state while in planning search partial plan is node.\n",
    "\n",
    "    Open condition is a precondition of a step not yet fullfilled.\n",
    "    \n",
    "    Operator on partial plans\n",
    "    - add a link : from an existing action to a open condition.\n",
    "    - add a step : to fullfill an open condition\n",
    "    - order one step wrt another\n",
    "        \n",
    "    Gradually move from vague/incomplete plan to complete plan, correct plan.\n",
    "    \n",
    "**Plan**\n",
    "\n",
    "1. Set of plan steps (each operator for the problem)\n",
    "2. Set of steps ordering constraints (eg. A before B)\n",
    "3. Set of variable binding constraints (eg. v=x, where v variable and x constant or other variable)\n",
    "4. set of causal links (A achieves c for B)\n",
    "\n",
    "**POP Algorithm is sound, complete and systematic.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Logic\n",
    "\n",
    "1. A superset of boolean Logic. Not everything is between True and False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
