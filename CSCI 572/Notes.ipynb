{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713419e5",
   "metadata": {},
   "source": [
    "URL encode and decode: https://net-load.com/url-ascii-encoding-reference/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0708dfe",
   "metadata": {},
   "source": [
    "**Surface/Deep/Dark Web**\n",
    "\n",
    "1. **Surface Web**: Accessible through crawlers\n",
    "2. **Deep Web**: Contains 90% of on the internet, not accessible through surface web crawler. Financial Records, Medical Records, Legal Documents\n",
    "3. **Dark Web**: A part of the Deep Web accessible only through certain browser such as Tor designed to maintain anomynity. Deep web technologies has zero involvement with Dark Web. Drug Traffic Sites, private communications, illegal information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2980aac4",
   "metadata": {},
   "source": [
    "**Search Engine Evaluation**\n",
    "1. Precision    \n",
    "        \n",
    "        #(relevant items retrived) / #(all retrieved items)\n",
    "        #tp/(tp+fp)\n",
    "\n",
    "2. Recall\n",
    "       \n",
    "        #(relevant items retrieved) / #(all relevant items)\n",
    "        #tp/(tp+fn)\n",
    "     \n",
    "3. Mean average Precision\n",
    "        \n",
    "        Average precision        average of precision\n",
    "             of              =   for all every index\n",
    "         the documents           in extract \n",
    "            \n",
    "         \n",
    "         Mean average precision for a set of queries is the man of average precision scores for each query.\n",
    "         \n",
    "         MAP = sum_q=1_to_Q AveP(q) / Q\n",
    "         \n",
    "         Q is number of queries\n",
    "           \n",
    "        \n",
    "4. Harmonic Mean and F Measure\n",
    "\n",
    "        # Harmonic means tend strongly toward least element in list\n",
    "        # HM > GM > AM\n",
    "        # F = 2*Recall*Precision / (Recall + Precision)\n",
    "        \n",
    "5. Discounted Cumulative Gain\n",
    "    \n",
    "        DCG penalize more if highly relevant document appear lower in search result list\n",
    "        \n",
    "        DCG = \\sum_i_to_p rel_i / log_2(i+1)\n",
    "            \n",
    "        rel_i is relevance of result at position i\n",
    "        \n",
    "6. Click-through on first result\n",
    "7. Study of user behaviour in lab\n",
    "8. A/B testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df184362",
   "metadata": {},
   "source": [
    "### Crawlers\n",
    "\n",
    "1. Google - GoogleBot\n",
    "2. Bing - BingBot, Adidxbot, MSNbot, MSNBotMedia, BingPreview\n",
    "\n",
    "**Issues**\n",
    "1. Quality - best pages first\n",
    "2. Efficiency - avoid duplication\n",
    "3. Etiquette - behave politely by not disturbing a website performance.\n",
    "4. Coverage - What percentage of web to cover\n",
    "5. relative coverage - how much do competitors do\n",
    "6. Freshness - How much has changed?\n",
    "\n",
    "\n",
    "**robots.txt**: Defines limitations for a web crawler as it visits a website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51094aa",
   "metadata": {},
   "source": [
    "**URL Normalizing :**\n",
    "1. Convert the scheme and host to lower case\n",
    "2. Capitalize letter in escape seequences, all letters within a percent-encoding triplet (e.g. \"%3A\") are case-insensitive, and should be capitalized.\n",
    "3. Decode percent-encoded octets of unreserved characters.\n",
    "4. Remove the default port. The default port (port 80 for \"http\" scheme)\n",
    "\n",
    "**Spider trap** When crawler re-visits the same page over and over again. Most well-known spider trap is one created by the use of Session ID's.\n",
    "\n",
    "**Spam Web Pages**\n",
    "1. First generation: high number of repeated terms \n",
    "2. Second generation: Cloaking is when web server detects a request from a crawler, it returns a different page. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e9f08",
   "metadata": {},
   "source": [
    "**Measuing Crawler**\n",
    "1. Improving URL parsing speed\n",
    "2. Imprving network bandwidth\n",
    "3. Improve fault tolerance\n",
    "\n",
    "**Issues with crawler**\n",
    "1. Refresh strategies: how often is the process re-started\n",
    "2. Detecting duplicate pages\n",
    "3. Detecting mirror sites\n",
    "4. Speeding up DNS lookup\n",
    "            \n",
    "            DNS Caching: build a caching server that retains IP-domain name mappings previously discovered\n",
    "            \n",
    "            Pre-fetching client: once page is parsed, immediately make DNS resolution request to caching server.\n",
    "        \n",
    "5. URL normalization\n",
    "6. Handling malformed HTML\n",
    "\n",
    "**Speed up Crawler**\n",
    "1. Multi-threading\n",
    "2. Distributed crawling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0d2a7",
   "metadata": {},
   "source": [
    "### De-Duplication\n",
    "\n",
    "    Process of identifying and avoiding essentially identical web pages while crawling.\n",
    "    \n",
    "    * Smarter Crawling - avoid giving duplicate resuls. allow fetching from fastest or freshest server.\n",
    "    * Better Connectivity analysis - Combine in-links from multiple mirro-sites to get accurate pageranks. Avoid double counting out-links \n",
    "    * Add redundancy in result listings:\n",
    "    * Reduce crawl time: No need to crawl identical pages.\n",
    "    * Ideally: Given web page scale and complexity, priority must be given to content that has not already been seen before or has recently changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a6069",
   "metadata": {},
   "source": [
    "**Duplicate Problem: Exact Match**\n",
    "\n",
    "    * Solution: compute fingerpring using hashing, Cryptocraphic Hash Function such as MD5, SHA-1, SHA-2, SHA-3, RIPEMD-160.\n",
    "    * Useful for URL matching and also work for detecting identical web pages.\n",
    "    * Hashes can be stored in sorted order for logN access\n",
    "    \n",
    "    \n",
    "**Near Duplicate Problem: Approximation Match**\n",
    "    \n",
    "    * Solution: Compute syntatic similarity with an edit distance measure.\n",
    "    * Use a similarity threshold to detect near duplicates\n",
    "    1. Produce fingerprint and test for similarity:\n",
    "        Convert web docs into set of features (n dim vector) and transform this into f-bit fingerprint.\n",
    "        SimHash or Hamming Distance to compute fingerprint\n",
    "        Compare fingerprint and look for difference in at most k bits\n",
    "    2. Compute subsets of words (called shingles) and test for similarity of sets.\n",
    "         Distance measure: \n",
    "             Euclidean distance\n",
    "             Jaccard distance\n",
    "             Cosine distance\n",
    "             Edit distance\n",
    "             Hamming distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1aa955",
   "metadata": {},
   "source": [
    "**Information Retrieval**\n",
    "\n",
    "1. Boolean Model\n",
    "2. Vector Space Model\n",
    "    \n",
    "        - TF-IDF (TF = frequecy of term in document) (IDF = log(N/num of docs containing term) )\n",
    "         \n",
    "        - tf_i * idf_i = (1+log(tf_ij))*log2( N/df_i )\n",
    "        \n",
    "        Then\n",
    "        Cosine Similarity\n",
    "        \n",
    "3. Lexicon and text normalization\n",
    "\n",
    "          - Stemming\n",
    "          - Stop words removal\n",
    "          - Tokenization\n",
    "          - Capitalization\n",
    "          - Case folding\n",
    "          - Synonyms\n",
    "          - similar sounding words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d6b22",
   "metadata": {},
   "source": [
    "**Zipf's Law**\n",
    "    \n",
    "    1. Frequency of any word is inversely proportional to rank in the frequency table.\n",
    "    2. Most frequent word will occur approx twice as oftern as second most frequent word.\n",
    "    3. Zipf's law is power law with c=-1\n",
    "        y = kx^c or y = k/x\n",
    "    \n",
    "**Heaps Law**\n",
    "   \n",
    "    Dictionary size continues to increase with more documents in the collections, rather than a maximum vocab size being reached.\n",
    "    \n",
    "    1. V = K n^b   V is vocab size, n is number of word\n",
    "    \n",
    "**Apache Tika :** Detects and extract metadata and text from thousands of file types using a single interface. Can be useful for search engines.\n",
    "\n",
    "**Stemming :** refers to a crude heuristic process that chops off the end in word to achieve a common base correctly most of time.\n",
    "\n",
    "**Lemmatization :** refers to use of vocubulary and morphological analysis of words normalyy aims to remove inflectional endings and to return base or dictionary form of word.\n",
    "\n",
    "**Soundex :** Soundex is phonetic algorithm for indexing names by their sound when pronounced in english."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ce65a",
   "metadata": {},
   "source": [
    "### Inverted Index\n",
    "\n",
    "An inverted index is typically composed of a vector containing all distinct words of the text collection in lexicographical order (vocabulary).\n",
    "\n",
    "Terms in inverted file index may be refined:\n",
    " - Case folding, Stemming/lemmatization, Stop words\n",
    " \n",
    "* For each term T, we must store a list of all documents that contain T.\n",
    "* Linked list are generally preferred to arrays\n",
    "    \n",
    "      - Dynamic Space allocation\n",
    "      - Insertion of terms into documents easy\n",
    "      - There is space overhead of pointers, though this is not too serious.\n",
    "      \n",
    "* **Algo 1 :** Intersect. Process in order of increasing frequency of occurrence.\n",
    "* **Algo 2 :** Faster. Skip Pointers which are added at indexing time. \n",
    "\n",
    "* **Handling Longer :** Queries longer than 2 words have to be broken in bi-word segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a99ffb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
