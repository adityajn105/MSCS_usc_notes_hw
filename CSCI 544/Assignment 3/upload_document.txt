Complete this document and upload along with your prediction results and your code.

### Method Name ###
Use a two-part name to describe your method, e.g. bag-of-words + FFNN, cipherword word2vec + BiLSTM, etc.

Ans: TF-IDF + SVM

### Representation of sentence ###
Use up to 3 sentences to describe how you obtained the representation/features of each ciphertext sentence. E.g., bag-of-words? trained a word2vec or fasttext on all sentences from scratch?

Ans: I have used TF-IDF vector to represent each sentence. TF-IDF. It takes into account not only frequency of word in each sentence but also entire corpus. It also weight down the words which occur quite often in most of the documents.
 
### Classifier ###
Use up to 5 sentences to describe how you implemented your classifier. What encoder did you use and what was the learning objective?

Ans: I have used Support vector machines (SVM) as my classifier. Radial Basis Function is used as a kernel to fit the model. Sentence is encoded in form of tfidfvector and for that I have used TFIDF Vectorizer of sklearn. Learning objective for SVM is maximizing seperating hyperplane for two classes. 

### Training & Development ###
Up to 5 sentences: how did you evaluate your solution using the dev set before submitting to the leaderboard? What are some key hyperparameter values (e.g., optimizer, learning rate, batch size, etc.)? How did you terminate the training (using a fixed #epochs, early stopping based on dev set performance)?

Ans: I trained SVM model on train set and evaluated it on dev set using accuracy matric. For SVM some hyperparameters are choice of kernel (I selected "rbf"), regularization parameter "C" (100). I have used GridSearch for finding optimal values of those hyperparameters. For terminating training there is another hyperparameter called tolerance of stopping criterion which I set to default (i.e. 1e-3). Final for test set, I trained my SVM model again on both train+dev and then calculated labels for it.


### Other methods ###
Did you try other methods than the submitted one?

Ans: I have tried following more methods:
1. Embedding Layer + Bi-LSTM with binary crossentropy Loss
2. TF-IDF + GBM
3. TF-IDF + Artificial Neural Network with binary crossentropy Loss
4. TF-IDF + Logistic Regression

### Packages ###
List the key python packages you have used in this assignment.

Ans: Following are some key libraries
1. scikit-learn
2. numpy
3. tensorflow
4. keras
