{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "23184e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_input = \"hmm-training-data/it_isdt_train_tagged.txt\"\n",
    "path_to_predict = \"hmm-training-data/ja_gsd_train_tagged.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "61b49953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13121"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "with open(path_to_input, \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        sentences.append( line.strip().split(\" \") )\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e569f8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seperate_tag_word(word_tag):\n",
    "    i = len(word_tag)-1\n",
    "    while word_tag[i] != \"/\": i -= 1\n",
    "    return word_tag[:i], word_tag[i+1:]\n",
    "\n",
    "emission_list = defaultdict(list)\n",
    "for sentence in sentences:\n",
    "    for word_tag in sentence:\n",
    "        word, tag = seperate_tag_word(word_tag)\n",
    "        emission_list[tag].append(word)\n",
    "\n",
    "sorted_tag_list = []\n",
    "vocabulary = set()\n",
    "emission_matrix = defaultdict(lambda: defaultdict(float))\n",
    "for tag, words in emission_list.items():\n",
    "    v = 1/len(words)\n",
    "    sorted_tag_list.append( (v, tag) )\n",
    "    for word in words:\n",
    "        emission_matrix[tag][word] += v\n",
    "        vocabulary.add(word)\n",
    "len(emission_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "55c0e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tag_list = [ t for _,t in sorted(sorted_tag_list) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "37cbed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_list = defaultdict(list)\n",
    "for sentence in sentences:\n",
    "    n = len(sentence)\n",
    "    tag_list = []\n",
    "    for word_tag in sentence:\n",
    "        tag = seperate_tag_word(word_tag)[1]\n",
    "        tag_list.append(tag)\n",
    "    \n",
    "    transition_list[\"\"].append( tag_list[0] )\n",
    "    for i in range(1,n):\n",
    "        transition_list[ tag_list[i-1] ].append( tag_list[i] )\n",
    "\n",
    "transition_matrix = defaultdict(lambda: defaultdict(float))\n",
    "for prev_tag, tags in transition_list.items():\n",
    "    n = len(tags)+len(sorted_tag_list)\n",
    "    count = dict()\n",
    "    for tag in tags: count[tag] = count.get(tag,0)+1\n",
    "    for tag in sorted_tag_list:\n",
    "        transition_matrix[prev_tag][tag] = (count.get(tag,0)+1)/n\n",
    "len(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2463aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model = {\n",
    "    \"transition\": transition_matrix,\n",
    "    \"emission\": emission_matrix,\n",
    "    \"vocab\": list(vocabulary),\n",
    "    \"tags\": sorted_tag_list  \n",
    "}\n",
    "with open(\"hmmmodel.txt\", \"w\") as fp:\n",
    "    json.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1218eb01",
   "metadata": {},
   "source": [
    "## Viterbi Decoding Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9f08a784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_decode = \"hmm-training-data/it_isdt_dev_raw.txt\"\n",
    "sentences = []\n",
    "with open(path_to_decode, \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        sentences.append( line.strip().split(\" \") )\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1634ac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 39, 28307, 1)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"hmmmodel.txt\", \"r\") as fp:\n",
    "    model = json.load(fp)\n",
    "transition = model[\"transition\"]\n",
    "emission = model[\"emission\"]\n",
    "vocab = set(model[\"vocabulary\"])\n",
    "sorted_tags = model[\"tags\"]\n",
    "len(transition), len(emission), len(vocab), len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "de7fc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sentence, emission, transition, sorted_tags, vocab):\n",
    "    probability = defaultdict(float)\n",
    "    backpointer = dict()\n",
    "    t_n = len(sorted_tags)\n",
    "    \n",
    "    n = len(sentence)\n",
    "    if sentence[0] not in vocab:\n",
    "        for tag in sorted_tags[:t_n//2]:\n",
    "            probability[ (tag,0) ] = transition[\"\"][tag]\n",
    "            backpointer[ (tag,0) ] = None\n",
    "    else:\n",
    "        for tag in sorted_tags:\n",
    "            if sentence[0] not in emission[tag]: continue\n",
    "            probability[ (tag,0) ] = transition[\"\"][tag]*emission[tag][sentence[0]]\n",
    "            backpointer[ (tag,0) ] = None\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        for prev_tag in sorted_tags:\n",
    "            if sentence[i] not in vocab:\n",
    "                for curr_tag in sorted_tags[:t_n//2]:\n",
    "                    prob = probability[(prev_tag,i-1)]*transition[prev_tag][curr_tag]\n",
    "                    if prob > probability[ (curr_tag,i) ]:\n",
    "                        probability[ (curr_tag,i) ] = prob\n",
    "                        backpointer[ (curr_tag,i) ] = prev_tag\n",
    "            else:\n",
    "                for curr_tag in sorted_tags:\n",
    "                    if sentence[i] not in emission[curr_tag]:\n",
    "                        prob = 0\n",
    "                    else:\n",
    "                        prob = probability[(prev_tag,i-1)]*transition[prev_tag][curr_tag]*emission[curr_tag][sentence[i]]\n",
    "                    \n",
    "                    if prob > probability[ (curr_tag,i) ]:\n",
    "                        probability[ (curr_tag,i) ] = prob\n",
    "                        backpointer[ (curr_tag,i) ] = prev_tag\n",
    "    \n",
    "    max_probable_last_tag, prob = None, 0\n",
    "    for tag in sorted_tags:\n",
    "        if probability.get( (tag,n-1), 0 ) > prob:\n",
    "            prob = probability[(tag,n-1)]\n",
    "            max_probable_last_tag = tag\n",
    "    \n",
    "    return backpointer, max_probable_last_tag, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "83098eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_via_backpointer(backpointer, last_tag, n):\n",
    "    tags, i = [last_tag], n-1\n",
    "    while backpointer[ (last_tag, i) ] != None:\n",
    "        last_tag = backpointer[ (last_tag, i) ]\n",
    "        tags.append(last_tag)\n",
    "        i -= 1\n",
    "    return tags[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "beac0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Corriere Sport da pagina 23 a pagina 26\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5a933baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "backpointer, last_tag, n = decode(s, emission, transition, sorted_tag_list, vocab)\n",
    "tags = decode_via_backpointer(backpointer, last_tag, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "002221fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corriere/SP Sport/SP da/E pagina/S 23/N a/E pagina/S 26/N'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([f\"{word}/{tag}\" for word, tag in zip(s, tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2a6409a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = \"hmmoutput.txt\"\n",
    "truth = \"hmm-training-data/it_isdt_dev_tagged.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ba7a1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tags = []\n",
    "with open(prediction, \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        prediction_tags.extend( line.strip().split(\" \") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3d28eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corriere/SP',\n",
       " 'Sport/SP',\n",
       " 'da/E',\n",
       " 'pagina/S',\n",
       " '23/N',\n",
       " 'a/E',\n",
       " 'pagina/S',\n",
       " '26/N',\n",
       " 'I/RD',\n",
       " 'tre/N']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "792b064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tags = []\n",
    "with open(truth, \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        true_tags.extend( line.strip().split(\" \") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0111ed28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corriere/SP',\n",
       " 'Sport/SP',\n",
       " 'da/E',\n",
       " 'pagina/S',\n",
       " '23/N',\n",
       " 'a/E',\n",
       " 'pagina/S',\n",
       " '26/N',\n",
       " 'I/RD',\n",
       " 'tre/N']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "45fbcc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305508901578771"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for p,t in zip(prediction_tags, true_tags):\n",
    "    if p==t: correct+=1\n",
    "correct/len(true_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
